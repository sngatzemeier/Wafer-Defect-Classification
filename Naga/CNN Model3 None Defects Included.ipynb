{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model 3\n",
    "## Selected images with patterns and 3% None defect pattern data included. All images resized to 42x42. Accuracy of 0.32 achieved. No data augmentation done.\n",
    "\n",
    "This code is written to ingest WM811K dataset and get trained on defect patterns and be able to distinguish and group wafers into two groups - defect pattern vs no pattern. Data was resized to 60x60. Runs existing data defect patterns without any additional data added to rebalance class. \n",
    "\n",
    "Sources:\n",
    "1. Wafer defect classification by deep learning code: Ashadullah Shawon: https://www.kaggle.com/shawon10/wafer-defect-classification-by-deep-learning\n",
    "2. Defect detection in wafer maps: Paul Bassaler: https://www.kaggle.com/paulbassaler/defect-detection-in-wafer-bin-maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.22.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.10.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/nagachandrasekaran/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, Input, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import modeling libraries.\n",
    "import sklearn as sk\n",
    "#sklearn.__version__\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.transform import resize as sk_resize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811457 entries, 0 to 811456\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   waferMap        811457 non-null  object \n",
      " 1   dieSize         811457 non-null  float64\n",
      " 2   lotName         811457 non-null  object \n",
      " 3   waferIndex      811457 non-null  float64\n",
      " 4   trianTestLabel  811457 non-null  object \n",
      " 5   failureType     811457 non-null  object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 37.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waferMap</th>\n",
       "      <th>dieSize</th>\n",
       "      <th>lotName</th>\n",
       "      <th>waferIndex</th>\n",
       "      <th>trianTestLabel</th>\n",
       "      <th>failureType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151806</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>lot9813</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529092</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1,...</td>\n",
       "      <td>515.0</td>\n",
       "      <td>lot33123</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540316</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>686.0</td>\n",
       "      <td>lot33738</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421881</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>723.0</td>\n",
       "      <td>lot25329</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535708</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,...</td>\n",
       "      <td>710.0</td>\n",
       "      <td>lot33474</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 waferMap  dieSize   lotName  \\\n",
       "151806  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   3532.0   lot9813   \n",
       "529092  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1,...    515.0  lot33123   \n",
       "540316  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,...    686.0  lot33738   \n",
       "421881  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1,...    723.0  lot25329   \n",
       "535708  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,...    710.0  lot33474   \n",
       "\n",
       "        waferIndex trianTestLabel failureType  \n",
       "151806        14.0             []          []  \n",
       "529092        22.0             []          []  \n",
       "540316        12.0             []          []  \n",
       "421881         4.0             []          []  \n",
       "535708        14.0             []          []  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the full data file that is stored locally. Look at information and data details\n",
    "\n",
    "df=pd.read_pickle(\"LSWMD.pkl\")\n",
    "df.info()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique die size values\n",
      " 710.0     66961\n",
      "515.0     45725\n",
      "712.0     42572\n",
      "1513.0    39322\n",
      "776.0     29513\n",
      "Name: dieSize, dtype: int64\n",
      "\n",
      "Sample of unique dies dize values [1683. 2460.  533. ...  551.  554.  550.]\n",
      "Dies size value that occurs the most 710.0\n"
     ]
    }
   ],
   "source": [
    "# From the dataset we have wafers with different die size and count. Look at details.\n",
    "print(\"Number of unique die size values\\n\", df['dieSize'].value_counts().head())\n",
    "print(\"\\nSample of unique dies dize values\", pd.unique(df['dieSize']))\n",
    "print(\"Dies size value that occurs the most\", df['dieSize'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die size dimension in descending order\n",
      " (32, 29)    108687\n",
      "(25, 27)     64083\n",
      "(49, 39)     39323\n",
      "(26, 26)     30078\n",
      "(30, 34)     29513\n",
      "             ...  \n",
      "(43, 41)         1\n",
      "(49, 67)         1\n",
      "(26, 44)         1\n",
      "(88, 62)         1\n",
      "(54, 64)         1\n",
      "Name: waferMapDim, Length: 632, dtype: int64\n",
      "Die size dimension in descending order\n",
      " (42, 42)    811457\n",
      "Name: resize_waferMapDim, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Measuring the wafer map dimensions and adding a column called waferMapDim\n",
    "# waferMap value is a numpy array with 0, 1, 2 values. 0-no data, 1-pure pixel die, 2-defect die\n",
    "# Each die is represented by a pixel value. So, size of this waferMap array is different\n",
    "\n",
    "# This function was used to find the original wafer image dimensions and sort them\n",
    "def find_dim(x):\n",
    "    dim0=np.size(x,axis=0)\n",
    "    dim1=np.size(x,axis=1)\n",
    "    return dim0,dim1\n",
    "\n",
    "df['waferMapDim']=df.waferMap.apply(find_dim)\n",
    "print(\"Die size dimension in descending order\\n\", df['waferMapDim'].value_counts().sort_values(ascending=False))\n",
    "\n",
    "# Build function to resize images. Resizing to 28x28\n",
    "x_dim = 42\n",
    "y_dim = 42\n",
    "\n",
    "def resize_wafers(row):\n",
    "    base_map = row['waferMap']\n",
    "    resize_map = sk_resize(base_map*1024,[x_dim,y_dim], anti_aliasing=True)\n",
    "    return resize_map\n",
    "\n",
    "df['resize_waferMap'] = df.apply (lambda row: resize_wafers(row), axis=1)\n",
    "\n",
    "# With resized images to 42x42, we can get all images to be same and keep sample size high\n",
    "df['resize_waferMapDim']=df.resize_waferMap.apply(find_dim)\n",
    "print(\"Die size dimension in descending order\\n\", df['resize_waferMapDim'].value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waferMap</th>\n",
       "      <th>dieSize</th>\n",
       "      <th>lotName</th>\n",
       "      <th>waferIndex</th>\n",
       "      <th>trianTestLabel</th>\n",
       "      <th>failureType</th>\n",
       "      <th>waferMapDim</th>\n",
       "      <th>resize_waferMap</th>\n",
       "      <th>resize_waferMapDim</th>\n",
       "      <th>failureNum</th>\n",
       "      <th>trainTestNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>731566</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1,...</td>\n",
       "      <td>741.0</td>\n",
       "      <td>lot44298</td>\n",
       "      <td>18.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(33, 29)</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145810</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,...</td>\n",
       "      <td>712.0</td>\n",
       "      <td>lot9380</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(30, 31)</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481829</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,...</td>\n",
       "      <td>796.0</td>\n",
       "      <td>lot29856</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(31, 33)</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82599</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>lot5909</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(56, 41)</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368232</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2,...</td>\n",
       "      <td>592.0</td>\n",
       "      <td>lot22003</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(29, 27)</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>(42, 42)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 waferMap  dieSize   lotName  \\\n",
       "731566  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1,...    741.0  lot44298   \n",
       "145810  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,...    712.0   lot9380   \n",
       "481829  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,...    796.0  lot29856   \n",
       "82599   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1801.0   lot5909   \n",
       "368232  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2,...    592.0  lot22003   \n",
       "\n",
       "        waferIndex trianTestLabel failureType waferMapDim  \\\n",
       "731566        18.0             []          []    (33, 29)   \n",
       "145810         7.0             []          []    (30, 31)   \n",
       "481829        13.0             []          []    (31, 33)   \n",
       "82599          6.0             []          []    (56, 41)   \n",
       "368232        21.0             []          []    (29, 27)   \n",
       "\n",
       "                                          resize_waferMap resize_waferMapDim  \\\n",
       "731566  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           (42, 42)   \n",
       "145810  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           (42, 42)   \n",
       "481829  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           (42, 42)   \n",
       "82599   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           (42, 42)   \n",
       "368232  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           (42, 42)   \n",
       "\n",
       "       failureNum trainTestNum  \n",
       "731566         []           []  \n",
       "145810         []           []  \n",
       "481829         []           []  \n",
       "82599          []           []  \n",
       "368232         []           []  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-arranging the data. Creating nuerical values for failure type and train/test type\n",
    "\n",
    "df['failureNum']=df.failureType\n",
    "df['trainTestNum']=df.trianTestLabel\n",
    "mapping_type={'Center':0,'Donut':1,'Edge-Loc':2,'Edge-Ring':3,'Loc':4,'Random':5,'Scratch':6,'Near-full':7,'none':8}\n",
    "mapping_traintest={'Training':0,'Test':1}\n",
    "df=df.replace({'failureNum':mapping_type, 'trainTestNum':mapping_traintest})\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wafers with label 172950\n",
      "Wafers with defect patterns 25519\n",
      "Wafers without defect patterns 147431\n"
     ]
    }
   ],
   "source": [
    "# Split the database into three buckets: Wafers with labels, Wafers with pattern defect, Wafers without patterns\n",
    "\n",
    "#Wafers with labels are wafers that have some defect label provided. This includes \"none\" category as well\n",
    "df_withlabel = df[(df['failureNum']>=0) & (df['failureNum']<=8)]\n",
    "df_withlabel = df_withlabel.reset_index()\n",
    "#Wafers with pattern are wafers that have some pattern. None is excluded\n",
    "df_withpattern = df[(df['failureNum']>=0) & (df['failureNum']<=7)]\n",
    "df_withpattern = df_withpattern.reset_index()\n",
    "#Wafers with label but no defect patterns. None category\n",
    "df_nonpattern = df[(df['failureNum']==8)]\n",
    "print(\"Wafers with label\", df_withlabel.shape[0])\n",
    "print(\"Wafers with defect patterns\", df_withpattern.shape[0])\n",
    "print(\"Wafers without defect patterns\", df_nonpattern.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a significant number of wafers without labels from the total 811K wafers. For wafers with labels, maority of wafers have no defect pattern. So, most of this data can be thrown out and we can go with a smaller subset of data for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29950, 42, 42) (29950, 1)\n"
     ]
    }
   ],
   "source": [
    "# If we use full dataframe df, there are too many unlabeled values\n",
    "# Even if we eliminate unlabeled values, we still have lot of none defects (147431). \n",
    "# Remove 90% of \"none defects\" () and throw away unlabeled values \n",
    "\n",
    "N=143000 #97% of 147431 data points. Throw this away at random\n",
    "#Select labeled data and throw away 97% of none defects at random. Create smaller dataframe\n",
    "sub_df = df_withlabel.drop(df_withlabel[df_withlabel['failureNum'].eq(8)].sample(N).index)\n",
    "#sub_df = df_withpattern.loc[df_withpattern['waferMapDim'] == (26, 26)]\n",
    "#sub_df = df_withpattern\n",
    "\n",
    "Imlist = np.ones((1, 42, 42))\n",
    "label = []\n",
    "\n",
    "for i in range(len(sub_df)):\n",
    "    # Remove data without any labels\n",
    "    if len(sub_df.iloc[i,:]['failureType']) == 0:\n",
    "        continue\n",
    "    Imlist = np.concatenate((Imlist, sub_df.iloc[i,:]['resize_waferMap'].reshape(1, 42, 42)))\n",
    "    label.append(sub_df.iloc[i,:]['failureType'][0][0])\n",
    "    \n",
    "#The first elemet in Imlist is just composed with ones, so it isn't intersesting, let's remove it\n",
    "Imlist=Imlist[1:]\n",
    "label=np.array(label).reshape((-1,1)) #Column of labels\n",
    "\n",
    "#We have all the values of the pixels: 0.0 is for the exterior ofthe wafer map\n",
    "#2.0 is for the local impure pixel and 1.0 is for a pure pixel of the wafer map\n",
    "\n",
    "print(np.shape(Imlist),np.shape(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29950, 42, 42, 1) 29950\n",
      "New_Imlist shape (29950, 42, 42, 3)\n"
     ]
    }
   ],
   "source": [
    "# Imlist is a numpy array with wafermap entries. Each entry has 28 rows and 28 columns\n",
    "# We now turn all this data into a single column of data\n",
    "# Each pixel value of each image is now separate and we can use it separately to process deep learning\n",
    "Imlist_redo=Imlist.reshape((-1,42,42,1)) \n",
    "print(np.shape(Imlist_redo), len(Imlist_redo))\n",
    "\n",
    "# In order to process deep learning, we have to use data composed by 1 only. In other words we have to\n",
    "# change the data of 0-blank, 1-clean diw, 2- defect die into a data set composed of 1 only. We have to\n",
    "# transform the dataset into a sequence of 1s for deep learning.\n",
    "# for 0.0 we will use [1, 0, 0]\n",
    "# for 1.0 we will use [0, 1, 0]\n",
    "# for 2.0 we will use [0, 0, 1]\n",
    "\n",
    "new_Imlist = np.zeros((len(Imlist_redo), 42, 42, 3)) \n",
    "\n",
    "for w in range(len(Imlist_redo)):\n",
    "    for i in range(42):\n",
    "        for j in range(42):\n",
    "            new_Imlist[w, i, j, int(Imlist_redo[w, i, j])] = 1\n",
    "\n",
    "print(\"New_Imlist shape\", np.shape(new_Imlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_Imlist is the final image list. It has 29950 images. Each image has a 28x28 pixel value. Each pixel has a x3 value. [1,0,0] representing 0, which is blank data. [0, 1, 0] represents a clean die. [0, 0, 1] represents a defective die. For this data set, we have all defects and none defect pattern wafers as well. Below we can see the distribution of data. Near-full has lowest data set followed by donut and random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep processed data separately to avoid repeated running\n",
    "new_Imlist_original = new_Imlist\n",
    "label_original = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center : 4294\n",
      "Donut : 555\n",
      "Edge-Loc : 5189\n",
      "Edge-Ring : 9680\n",
      "Loc : 3593\n",
      "Near-full : 149\n",
      "Random : 866\n",
      "Scratch : 1193\n",
      "none : 4431\n",
      "(29950, 42, 42, 3) (29950, 1)\n"
     ]
    }
   ],
   "source": [
    "#Now we can see the shape of our lists, just to now how big is our dataset\n",
    "for l in np.unique(label) :\n",
    "    print('{} : {}'.format(l, len(label[label==l])))\n",
    "print(np.shape(new_Imlist), np.shape(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20066, 42, 42, 3) (9884, 42, 42, 3) (20066, 9) (9884, 9)\n"
     ]
    }
   ],
   "source": [
    "#In order to process the test, we need a matrix of labels\n",
    "for i, l in enumerate(np.unique(label)):\n",
    "    label[label==l] = i\n",
    "    \n",
    "label = tf.keras.utils.to_categorical(label)\n",
    "\n",
    "#Now we know this information, we can lower the heavyness of the dataset, because it is too huge\n",
    "#new_IMLIST=new_Imlist[0:25000]\n",
    "#new_LABEL=label[0:25000]\n",
    "#test_Imlist=new_Imlist[25001:29950]\n",
    "#test_label=label[25001:29950]\n",
    "#print(np.shape(new_LABEL))\n",
    "\n",
    "im_train, im_test, label_train, label_test = train_test_split(new_Imlist, label, test_size=0.33, random_state=42)\n",
    "print(np.shape(im_train),np.shape(im_test),np.shape(label_train),np.shape(label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Convolutional based Encoder-Decoder Neural Network is an encoder-decoder neural network that consists of a encoder neural network and a decoder neural network in which one or both are convolutional neural networks. \n",
    "\n",
    "An encoder is a network that takes the input, and output a feature map/vector/tensor. These feature vector hold the information, the features, that represents the input. The decoder is again a network (usually the same network structure as encoder but in opposite orientation) that takes the feature vector from the encoder, and gives the best closest match to the actual input or intended output.\n",
    "\n",
    "Once trained, the encoder will gives feature vector for input that can be use by decoder to construct the input with the features that matter the most to make the reconstructed input recognizable as the actual input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic gradient descent is an iterative learning algorithm that uses a training dataset to update a model.\n",
    "# The batch size is a hyperparameter of gradient descent that controls the number of training samples to work \n",
    "# through before the model’s internal parameters are updated.The number of epochs is a hyperparameter of gradient \n",
    "# descent that controls the number of complete passes through the training dataset.\n",
    "\n",
    "# One epoch is when entire dataset is passed forward and backward through network once\n",
    "# But instead we train the dataset into different batches and pass it through\n",
    "# If 2000 data samples, divide into 500 batch size, it will take 4 iterations to run 1 epoch\n",
    "epoch=10\n",
    "batch_size=5000\n",
    "\n",
    "input_shape = (42, 42, 3)\n",
    "input_tensor = Input(input_shape)\n",
    "\n",
    "'''\n",
    "Set up the encode layer. Relu activation function, in this case, just keep the values we are convoluting, \n",
    "and it let us do the same for the output tensor created.\n",
    "'''\n",
    "encode = layers.Conv2D(64, (3,3), padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "'''\n",
    "Now that the encoder is settled, we have to code the latent vector, which is the last part of the encoder, and \n",
    "it aims to encapsulate the information for all input elements in order to help the decoder make accurate \n",
    "predictions. It acts as the initial hidden state of the decoder part of the model.\n",
    "'''\n",
    "\n",
    "#Only the highest value of a region is kept.Max pooling is keeping the most activated pixels (ones with the highest \n",
    "#values) and discards the rest.\n",
    "\n",
    "latent_vector = layers.MaxPool2D()(encode)\n",
    "encoder = models.Model(input_tensor, latent_vector)\n",
    "\n",
    "'''\n",
    "And now the decoder, and then connecting all the layers, to finally have the predicted output tensor. A stack of \n",
    "several recurrent units where each predicts an outputEach recurrent unit accepts a hidden state from the previous \n",
    "unit and produces and output as well as its own hidden state.\n",
    "'''\n",
    "\n",
    "#It is the transposed convolution layer, so the inverse step as the encoder\n",
    "decode_layer_1 = layers.Conv2DTranspose(64, (3,3), padding='same', activation='relu') \n",
    "\n",
    "#Repeats the rows and columns of the data by size[0] and size[1] respectively.\n",
    "decode_layer_2 = layers.UpSampling2D() \n",
    "output_tensor = layers.Conv2DTranspose(3, (3,3), padding='same', activation='sigmoid')\n",
    "\n",
    "#After having regarding the shape I needed for the start of the decoder, I have to define it.\n",
    "decoder_input = Input((21, 21, 64)) #decoder input was 13, 13, 64 for 26x26\n",
    "decode = decode_layer_1(decoder_input)\n",
    "decode = decode_layer_2(decode)\n",
    "\n",
    "decoder = models.Model(decoder_input, output_tensor(decode))\n",
    "\n",
    "#Now we have all the model, let's prepare the dataset, with normal wafers, and noised wafers, so that we will have some \n",
    "#data to make the machine predict their label\n",
    "\n",
    "encoded_Im = encoder.predict(new_Imlist)\n",
    "noised_encoded_Im = encoded_Im + np.random.normal(loc=0, scale=0.1, size = (len(encoded_Im), 21, 21, 64))\n",
    "# original code was 13, 13, 64 instead of 30, 30, 64 representing 26x26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this classification is not uniform and it creates a biased distribution of defect types in the dataset. We also do not have sufficient data that has labels and defect patterns. Once we remove unlabeled data and the wafers without defect patterns, we have only 877 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now create the real model we will use for the CNN test\n",
    "def create_model():\n",
    "    input_shape = (42, 42, 3)\n",
    "    input_tensor = Input(input_shape)\n",
    "\n",
    "    conv_1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(input_tensor)\n",
    "    conv_2 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(conv_1)\n",
    "    conv_3 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(conv_2)\n",
    "\n",
    "    flat = layers.Flatten()(conv_3)\n",
    "\n",
    "    dense_1 = layers.Dense(512, activation='relu')(flat)\n",
    "    dense_2 = layers.Dense(128, activation='relu')(dense_1)\n",
    "    output_tensor = layers.Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "    model = models.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer='Adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 - 75s - loss: 4.1343 - accuracy: 0.1444 - 75s/epoch - 25s/step\n",
      "Epoch 2/10\n",
      "3/3 - 65s - loss: 3.3715 - accuracy: 0.1653 - 65s/epoch - 22s/step\n",
      "Epoch 3/10\n",
      "3/3 - 62s - loss: 2.0953 - accuracy: 0.2575 - 62s/epoch - 21s/step\n",
      "Epoch 4/10\n",
      "3/3 - 61s - loss: 2.0671 - accuracy: 0.3254 - 61s/epoch - 20s/step\n",
      "Epoch 5/10\n",
      "3/3 - 62s - loss: 1.8582 - accuracy: 0.3254 - 62s/epoch - 21s/step\n",
      "Epoch 6/10\n",
      "3/3 - 61s - loss: 1.8886 - accuracy: 0.2694 - 61s/epoch - 20s/step\n",
      "Epoch 7/10\n",
      "3/3 - 61s - loss: 1.8286 - accuracy: 0.3254 - 61s/epoch - 20s/step\n",
      "Epoch 8/10\n",
      "3/3 - 1466s - loss: 1.8311 - accuracy: 0.3254 - 1466s/epoch - 489s/step\n",
      "Epoch 9/10\n",
      "3/3 - 63s - loss: 1.8255 - accuracy: 0.3254 - 63s/epoch - 21s/step\n",
      "Epoch 10/10\n",
      "3/3 - 64s - loss: 1.8224 - accuracy: 0.3254 - 64s/epoch - 21s/step\n",
      "2/2 - 8s - loss: 1.8177 - accuracy: 0.3177 - 8s/epoch - 4s/step\n",
      "Epoch 1/10\n",
      "3/3 - 59s - loss: 6.0322 - accuracy: 0.1725 - 59s/epoch - 20s/step\n",
      "Epoch 2/10\n",
      "3/3 - 58s - loss: 3.1062 - accuracy: 0.1503 - 58s/epoch - 19s/step\n",
      "Epoch 3/10\n",
      "3/3 - 57s - loss: 2.0448 - accuracy: 0.3237 - 57s/epoch - 19s/step\n",
      "Epoch 4/10\n",
      "3/3 - 58s - loss: 1.8893 - accuracy: 0.3237 - 58s/epoch - 19s/step\n",
      "Epoch 5/10\n",
      "3/3 - 58s - loss: 1.8391 - accuracy: 0.3237 - 58s/epoch - 19s/step\n",
      "Epoch 6/10\n",
      "3/3 - 58s - loss: 1.8220 - accuracy: 0.3237 - 58s/epoch - 19s/step\n",
      "Epoch 7/10\n",
      "3/3 - 57s - loss: 1.8196 - accuracy: 0.3237 - 57s/epoch - 19s/step\n",
      "Epoch 8/10\n",
      "3/3 - 57s - loss: 1.8186 - accuracy: 0.3237 - 57s/epoch - 19s/step\n",
      "Epoch 9/10\n",
      "3/3 - 59s - loss: 1.8176 - accuracy: 0.3237 - 59s/epoch - 20s/step\n",
      "Epoch 10/10\n",
      "3/3 - 61s - loss: 1.8162 - accuracy: 0.3237 - 61s/epoch - 20s/step\n",
      "2/2 - 8s - loss: 1.8250 - accuracy: 0.3211 - 8s/epoch - 4s/step\n",
      "Epoch 1/10\n",
      "3/3 - 193s - loss: 5.1877 - accuracy: 0.2071 - 193s/epoch - 64s/step\n",
      "Epoch 2/10\n",
      "3/3 - 718s - loss: 3.2250 - accuracy: 0.1510 - 718s/epoch - 239s/step\n",
      "Epoch 3/10\n",
      "3/3 - 1949s - loss: 2.1129 - accuracy: 0.3194 - 1949s/epoch - 650s/step\n",
      "Epoch 4/10\n",
      "3/3 - 227s - loss: 1.9545 - accuracy: 0.3194 - 227s/epoch - 76s/step\n",
      "Epoch 5/10\n",
      "3/3 - 220s - loss: 1.8737 - accuracy: 0.3194 - 220s/epoch - 73s/step\n",
      "Epoch 6/10\n",
      "3/3 - 218s - loss: 1.8356 - accuracy: 0.3194 - 218s/epoch - 73s/step\n",
      "Epoch 7/10\n",
      "3/3 - 219s - loss: 1.8290 - accuracy: 0.3194 - 219s/epoch - 73s/step\n",
      "Epoch 8/10\n",
      "3/3 - 219s - loss: 1.8246 - accuracy: 0.3194 - 219s/epoch - 73s/step\n",
      "Epoch 9/10\n",
      "3/3 - 337s - loss: 1.8233 - accuracy: 0.3194 - 337s/epoch - 112s/step\n",
      "Epoch 10/10\n",
      "3/3 - 60s - loss: 1.8219 - accuracy: 0.3194 - 60s/epoch - 20s/step\n",
      "2/2 - 8s - loss: 1.8124 - accuracy: 0.3297 - 8s/epoch - 4s/step\n",
      "[0.31768575 0.32112423 0.32969499]\n",
      "training accuracy =  0.32283498843510944\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=epoch, batch_size=batch_size, verbose=2) \n",
    "# 3-Fold Crossvalidation\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42) \n",
    "results = cross_val_score(model, im_train, label_train, cv=kfold)\n",
    "print(results)\n",
    "print(\"training accuracy = \", np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 - 103s - loss: 9.8158 - accuracy: 0.2370 - val_loss: 1.9053 - val_accuracy: 0.3240 - 103s/epoch - 21s/step\n",
      "Epoch 2/10\n",
      "5/5 - 100s - loss: 1.9536 - accuracy: 0.3228 - val_loss: 2.0347 - val_accuracy: 0.3240 - 100s/epoch - 20s/step\n",
      "Epoch 3/10\n",
      "5/5 - 99s - loss: 1.9555 - accuracy: 0.3228 - val_loss: 1.8364 - val_accuracy: 0.3240 - 99s/epoch - 20s/step\n",
      "Epoch 4/10\n",
      "5/5 - 99s - loss: 1.8531 - accuracy: 0.3228 - val_loss: 1.8230 - val_accuracy: 0.3240 - 99s/epoch - 20s/step\n",
      "Epoch 5/10\n",
      "5/5 - 99s - loss: 1.8311 - accuracy: 0.3228 - val_loss: 1.8284 - val_accuracy: 0.3240 - 99s/epoch - 20s/step\n",
      "Epoch 6/10\n",
      "5/5 - 99s - loss: 1.8286 - accuracy: 0.3228 - val_loss: 1.8212 - val_accuracy: 0.3240 - 99s/epoch - 20s/step\n",
      "Epoch 7/10\n",
      "5/5 - 98s - loss: 1.8232 - accuracy: 0.3228 - val_loss: 1.8185 - val_accuracy: 0.3240 - 98s/epoch - 20s/step\n",
      "Epoch 8/10\n",
      "5/5 - 101s - loss: 1.8230 - accuracy: 0.3228 - val_loss: 1.8197 - val_accuracy: 0.3240 - 101s/epoch - 20s/step\n",
      "Epoch 9/10\n",
      "5/5 - 99s - loss: 1.8226 - accuracy: 0.3228 - val_loss: 1.8140 - val_accuracy: 0.3240 - 99s/epoch - 20s/step\n",
      "Epoch 10/10\n",
      "5/5 - 98s - loss: 1.8218 - accuracy: 0.3228 - val_loss: 1.8188 - val_accuracy: 0.3240 - 98s/epoch - 20s/step\n"
     ]
    }
   ],
   "source": [
    "#Now we have done the training is done, let's validate the learning with the test dataset\n",
    "history = model.fit(im_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(im_test, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 12s - loss: 1.8188 - accuracy: 0.3240 - 12s/epoch - 6s/step\n",
      "Testing Accuracy: 0.3239579200744629\n"
     ]
    }
   ],
   "source": [
    "#And finally let's see what is the testing accuracy\n",
    "\n",
    "score = model.score(im_test, label_test)\n",
    "print('Testing Accuracy:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's now plot the differnces in the losses and the accuracies between the training and the test\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
