{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ViT Model for Classification of All Defects (including nones)\n",
    "ViT Model from Google [paper](https://arxiv.org/abs/2010.11929)\n",
    "using Keras implementation from faustomorales [GitHub](https://github.com/faustomorales/vit-keras)\n",
    "\n",
    "Data preprocessing:\n",
    "- Resized to 224x224 with no filters\n",
    "- None is randomly undersampled to 30,000.\n",
    "\n",
    "ViT model:\n",
    "- Size = L16\n",
    "- Patch size = 16\n",
    "- Using included top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RUN VIT REQUIREMENTS NOTEBOOK FIRST ####\n",
    "# need to install required packages to environment before running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17003,
     "status": "ok",
     "timestamp": 1645130034371,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "MMcWUHT5-eVD",
    "outputId": "00111a49-0a3c-4392-f905-805f1030b923"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, losses, optimizers, regularizers, callbacks\n",
    "from vit_keras import vit, utils\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.morphology import skeletonize, thin\n",
    "\n",
    "import helpers as helper\n",
    "from keras_model_s3_wrapper import *\n",
    "\n",
    "import boto3\n",
    "import pickle5 as pickle\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'wafer-capstone'\n",
    "my_bucket = s3.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables\n",
    "path = 'processed_data/vit'\n",
    "filename = 'WM-clean-vit224-undersampled'\n",
    "\n",
    "result_path = 'results_vit'\n",
    "model_id = 'vit-b16'\n",
    "data_id = '224-undersampled'\n",
    "note = '-p3' # -optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             total       used       free     shared    buffers     cached\n",
      "Mem:          240G        21G       219G        32M       294M        17G\n",
      "-/+ buffers/cache:       3.2G       236G\n",
      "Swap:           0B         0B         0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.150 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ids', 'labels', 'dataset', 'wafermap']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "from io import BytesIO\n",
    "start = time.time()\n",
    "\n",
    "data_key = f'{path}/{filename}.npz'\n",
    "data_obj = my_bucket.Object(data_key).get()['Body'].read()\n",
    "data = np.load(BytesIO(data_obj), allow_pickle=True)\n",
    "\n",
    "print('Wall time: {:.3f} seconds'.format(time.time() - start))\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             total       used       free     shared    buffers     cached\n",
      "Mem:          240G        21G       218G        32M       294M        17G\n",
      "-/+ buffers/cache:       3.5G       236G\n",
      "Swap:           0B         0B         0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 127.409 seconds\n",
      "Train: (47863, 224, 224, 3)\n",
      "Dev: (25942, 224, 224, 3)\n",
      "Test: (25943, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# prepare inputs\n",
    "start = time.time()\n",
    "\n",
    "x_train = data['wafermap'][data['dataset']=='train']\n",
    "x_val = data['wafermap'][data['dataset']=='dev']\n",
    "x_test = data['wafermap'][data['dataset']=='test']\n",
    "\n",
    "print('Wall time: {:.3f} seconds'.format(time.time() - start))\n",
    "print(f'Train: {x_train.shape}')\n",
    "print(f'Dev: {x_val.shape}')\n",
    "print(f'Test: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rIS8zJfn_aDO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0.03 seconds\n",
      "<class 'numpy.uint8'>\n",
      "0 0 0\n",
      "8 8 8\n"
     ]
    }
   ],
   "source": [
    "# prepare labels for supervised learning\n",
    "# note: make sure labels are integers if using sparse categorical cross entropy\n",
    "start = time.time()\n",
    "\n",
    "y_train = data['labels'][data['dataset']=='train']\n",
    "y_val = data['labels'][data['dataset']=='dev']\n",
    "y_test = data['labels'][data['dataset']=='test']\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# sanity check\n",
    "# expected: type = int, min = 0, max = 8\n",
    "print(type(y_train[0]))\n",
    "print(min(y_train), min(y_val), min(y_test))\n",
    "print(max(y_train), max(y_val), max(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             total       used       free     shared    buffers     cached\n",
      "Mem:          240G        35G       204G        32M       294M        17G\n",
      "-/+ buffers/cache:        17G       222G\n",
      "Swap:           0B         0B         0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1645130313542,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "UeaLkOM-XRZA",
    "outputId": "31d7455b-87b6-42d6-e2ac-00c598e47744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/vit_keras/utils.py:83: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vit-l16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "embedding (Conv2D)           (None, 14, 14, 1024)      787456    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 196, 1024)         0         \n",
      "_________________________________________________________________\n",
      "class_token (ClassToken)     (None, 197, 1024)         1024      \n",
      "_________________________________________________________________\n",
      "Transformer/posembed_input ( (None, 197, 1024)         201728    \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_0 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_1 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_2 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_3 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_4 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_5 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_6 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_7 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_8 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_9 ( ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_10  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_11  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_12  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_13  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_14  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_15  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_16  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_17  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_18  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_19  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_20  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_21  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_22  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_23  ((None, 197, 1024), (None 12596224  \n",
      "_________________________________________________________________\n",
      "Transformer/encoder_norm (La (None, 197, 1024)         2048      \n",
      "_________________________________________________________________\n",
      "ExtractToken (Lambda)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "head (Dense)                 (None, 9)                 9225      \n",
      "=================================================================\n",
      "Total params: 303,310,857\n",
      "Trainable params: 303,310,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fine-tune using pre-trained vit model\n",
    "image_size = 224\n",
    "model = vit.vit_l16(\n",
    "    image_size=image_size,\n",
    "    activation='softmax',\n",
    "    pretrained=True,\n",
    "    include_top=True,\n",
    "    pretrained_top=False,\n",
    "    classes=9\n",
    ")\n",
    "\n",
    "# # classification head similar to yu classify model\n",
    "# model = models.Sequential()\n",
    "# model.add(vit_model)\n",
    "# model.add(layers.Dense(384, activation='sigmoid', kernel_regularizer=regularizers.l2(0.000001)))\n",
    "# model.add(layers.Dense(96, activation='sigmoid', kernel_regularizer=regularizers.l2(0.000001)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pOAJW5ByhYCl"
   },
   "outputs": [],
   "source": [
    "# set model optimizer and metrics\n",
    "opt = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             total       used       free     shared    buffers     cached\n",
      "Mem:          240G        35G       204G        32M       294M        17G\n",
      "-/+ buffers/cache:        17G       222G\n",
      "Swap:           0B         0B         0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2992/2992 [==============================] - 2469s 825ms/step - loss: 0.8705 - accuracy: 0.7613 - val_loss: 0.4997 - val_accuracy: 0.8938\n",
      "Wall time: 2474.43 seconds\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=16, epochs=1)\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1645130877052,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "AfX0d7zyocFw",
    "outputId": "6af8efe7-c57b-4b8e-d103-4334230e2663"
   },
   "outputs": [],
   "source": [
    "# # visualize accuracy and loss history\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "\n",
    "# axs[0].plot(history.history['loss'])\n",
    "# axs[0].plot(history.history['val_loss'])\n",
    "# axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "# axs[0].legend(['Train', 'Val'])\n",
    "\n",
    "# axs[1].plot(history.history['accuracy'])\n",
    "# axs[1].plot(history.history['val_accuracy'])\n",
    "# axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "# axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model to S3\n",
    "# #s3_save_keras_model(model, f'{model_id}-{data_id}{note}')\n",
    "# s3_save_keras_model(model, 'vit-trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5266,
     "status": "ok",
     "timestamp": 1645130882314,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "iLQqDljamZTV",
    "outputId": "93e90021-8340-4f3d-a9f8-ca7fd6fdb56d"
   },
   "outputs": [],
   "source": [
    "# compute model results on test set\n",
    "start = time.time()\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0_djoisO5ru"
   },
   "outputs": [],
   "source": [
    "# generate predictions for model analysis\n",
    "start = time.time()\n",
    "y_pred = model.predict(x_test)\n",
    "y_max = np.argmax(y_pred, axis=1).astype(np.uint8)\n",
    "predictions = [y_max, y_pred]\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save predictions to local instance\n",
    "# # with open(f'{result_path}/{model_id}-{data_id}{note}.pkl', \"wb\") as f:\n",
    "# #     pickle.dump(predictions, f)\n",
    "# with open('vit-trial.pkl', \"wb\") as f:\n",
    "#     pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "helper.plot_confusion_matrix(y_test, y_max, mode='all', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot confusion matrix counts\n",
    "# helper.plot_confusion_matrix(y_test, y_max, mode='all', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colab_lenet_classify_all2.ipynb",
   "provenance": [
    {
     "file_id": "https://gist.github.com/mrgrhn/c6d2a157ebfc883e462f2d6e2ce2e3ce#file-lenet_tensorflow-ipynb",
     "timestamp": 1645028600895
    }
   ]
  },
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
