{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ViT Model for Classification of All Defects (including nones)\n",
    "ViT Model from Google [paper](https://arxiv.org/abs/2010.11929)\n",
    "using Keras implementation from faustomorales [GitHub](https://github.com/faustomorales/vit-keras)\n",
    "\n",
    "Data preprocessing:\n",
    "- Resized to 224x224 with no filters\n",
    "- None is randomly undersampled to 30,000.\n",
    "\n",
    "ViT model:\n",
    "- Size = B16\n",
    "- Patch size = 16\n",
    "- Using included top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN THE FOLLOWING ON TERMINAL FIRST ###\n",
    "# pip install --upgrade pip\n",
    "# pip install --upgrade tensorflow\n",
    "# pip install tensorflow_addons\n",
    "# pip install vit-keras\n",
    "# pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17003,
     "status": "ok",
     "timestamp": 1645130034371,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "MMcWUHT5-eVD",
    "outputId": "00111a49-0a3c-4392-f905-805f1030b923"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, losses, optimizers, regularizers, callbacks\n",
    "from vit_keras import vit, utils\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.morphology import skeletonize, thin\n",
    "\n",
    "import helpers as helper\n",
    "from keras_model_s3_wrapper import *\n",
    "\n",
    "import boto3\n",
    "import pickle5 as pickle\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'wafer-capstone'\n",
    "my_bucket = s3.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables for model\n",
    "path = 'processed_data/WM-clean224'\n",
    "result_path = 'results_vit'\n",
    "\n",
    "filename = 'WM-clean224'\n",
    "map_column = 'waferMap224'\n",
    "binarized = False\n",
    "\n",
    "model_id = 'vit_b16_includedtop'\n",
    "data_id = '224'\n",
    "note = '' # -optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.35 seconds\n",
      "Train: 25942\n",
      "Dev: 25943\n",
      "Sanity check: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# load dev and test sets\n",
    "# directly from S3 (using boto3 resource)\n",
    "start = time.time()\n",
    "\n",
    "dev_key = f'{path}/{filename}-dev.pkl'\n",
    "test_key = f'{path}/{filename}-test.pkl'\n",
    "\n",
    "dev = pickle.loads(my_bucket.Object(dev_key).get()['Body'].read())\n",
    "test = pickle.loads(my_bucket.Object(test_key).get()['Body'].read())\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "print(f\"Train: {len(dev)}\")\n",
    "print(f\"Dev: {len(test)}\")\n",
    "\n",
    "print(f\"Sanity check: {np.unique(dev[map_column][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 77.08 seconds\n",
      "Train: 47863\n",
      "Sanity check: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# load augmented 224x224 train dataset\n",
    "# # need to binarize and apply n=2 morphological thinning\n",
    "start = time.time()\n",
    "\n",
    "train_key = f'processed_data/WM-clean224/WM-clean224-train-all.pkl'\n",
    "train = pickle.loads(my_bucket.Object(train_key).get()['Body'].read())\n",
    "\n",
    "# remove augmented samples\n",
    "train = train[train.ID != 'A'].reset_index(drop=True)\n",
    "\n",
    "# def preprocess(x):\n",
    "#     ret, thresh_img = cv2.threshold(x, 1, 1, cv2.THRESH_BINARY)\n",
    "#     y = thin(thresh_img, 2)\n",
    "#     return y\n",
    "\n",
    "# train['thinMap2'] = train.waferMap224.apply(lambda x: preprocess(x))\n",
    "# train['thinMap2'] = train.thinMap2.apply(lambda x: x.astype(np.uint8))\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "print(f\"Train: {len(train)}\")\n",
    "print(f\"Sanity check: {np.unique(train[map_column][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train failure type distribution\n",
    "helper.defect_distribution(train, note='Train Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev failure type distribution\n",
    "helper.defect_distribution(dev, note='Dev Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test failure type distribution\n",
    "helper.defect_distribution(test, note='Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.38 seconds\n",
      "(47863,)\n"
     ]
    }
   ],
   "source": [
    "# prepare inputs\n",
    "# convert maps to grayscale images with size (224, 224, 3)\n",
    "start = time.time()\n",
    "\n",
    "def grayscale_convert(x):\n",
    "    if binarized:\n",
    "        img = np.uint8(x*255)\n",
    "    else:\n",
    "        img = np.uint8(x/2*255)\n",
    "    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    return img_bgr\n",
    "\n",
    "train['bgr'] = train[map_column].apply(lambda x: grayscale_convert(x))\n",
    "dev['bgr'] = dev[map_column].apply(lambda x: grayscale_convert(x))\n",
    "test['bgr'] = test[map_column].apply(lambda x: grayscale_convert(x))\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# sanity check\n",
    "print(train['bgr'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1645130310224,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "poThmiyAoHSi",
    "outputId": "b93c01b0-692b-4344-ce11-61da3613f166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.02 seconds\n",
      "(47863, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# prepare inputs\n",
    "start = time.time()\n",
    "\n",
    "x_train = np.stack(train['bgr'])\n",
    "x_val = np.stack(dev['bgr'])\n",
    "x_test = np.stack(test['bgr'])\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# sanity check\n",
    "# expected: (#rows, 224, 224, 3)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2769,
     "status": "ok",
     "timestamp": 1645130312987,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "hy_dVa44ZOLk",
    "outputId": "ffdd1312-46d9-44d7-bff5-083e7a5db085"
   },
   "outputs": [],
   "source": [
    "# # expand tensor and create dummy dimension at axis 3\n",
    "# # images in greyscale, so no channel dimension\n",
    "# start = time.time()\n",
    "\n",
    "# x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
    "# x_val = tf.expand_dims(x_val, axis=3, name=None)\n",
    "# x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
    "\n",
    "# print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# # sanity check\n",
    "# # expected: TensorShape([#rows, xdim, ydim, 1])\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rIS8zJfn_aDO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0.00 seconds\n",
      "<class 'numpy.uint8'>\n",
      "0 0 0\n",
      "8 8 8\n"
     ]
    }
   ],
   "source": [
    "# prepare labels for supervised learning\n",
    "# note: make sure labels are integers if using sparse categorical cross entropy\n",
    "start = time.time()\n",
    "\n",
    "y_train = np.asarray(train['classifyLabels']).astype(np.uint8)\n",
    "y_val = np.asarray(dev['classifyLabels']).astype(np.uint8)\n",
    "y_test = np.asarray(test['classifyLabels']).astype(np.uint8)\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# sanity check\n",
    "# expected: type = int, min = 0, max = 7\n",
    "print(type(y_train[0]))\n",
    "print(min(y_train), min(y_val), min(y_test))\n",
    "print(max(y_train), max(y_val), max(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1645130313542,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "UeaLkOM-XRZA",
    "outputId": "31d7455b-87b6-42d6-e2ac-00c598e47744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/vit_keras/utils.py:83: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vit-b16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "embedding (Conv2D)           (None, 14, 14, 768)       590592    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 196, 768)          0         \n",
      "_________________________________________________________________\n",
      "class_token (ClassToken)     (None, 197, 768)          768       \n",
      "_________________________________________________________________\n",
      "Transformer/posembed_input ( (None, 197, 768)          151296    \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_0 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_1 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_2 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_3 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_4 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_5 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_6 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_7 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_8 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_9 ( ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_10  ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoderblock_11  ((None, 197, 768), (None, 7087872   \n",
      "_________________________________________________________________\n",
      "Transformer/encoder_norm (La (None, 197, 768)          1536      \n",
      "_________________________________________________________________\n",
      "ExtractToken (Lambda)        (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "head (Dense)                 (None, 9)                 6921      \n",
      "=================================================================\n",
      "Total params: 85,805,577\n",
      "Trainable params: 85,805,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fine-tune using pre-trained vit model\n",
    "image_size = 224\n",
    "model = vit.vit_b16(\n",
    "    image_size=image_size,\n",
    "    activation='sigmoid',\n",
    "    pretrained=True,\n",
    "    include_top=True,\n",
    "    pretrained_top=False,\n",
    "    classes=9\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pOAJW5ByhYCl"
   },
   "outputs": [],
   "source": [
    "# set model optimizer and metrics\n",
    "opt = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=128, epochs=30)\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1645130877052,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "AfX0d7zyocFw",
    "outputId": "6af8efe7-c57b-4b8e-d103-4334230e2663"
   },
   "outputs": [],
   "source": [
    "# visualize accuracy and loss history\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].plot(history.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].legend(['Train', 'Val'])\n",
    "\n",
    "axs[1].plot(history.history['accuracy'])\n",
    "axs[1].plot(history.history['val_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to S3\n",
    "s3_save_keras_model(model, f'{model_id}-{data_id}{note}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5266,
     "status": "ok",
     "timestamp": 1645130882314,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "iLQqDljamZTV",
    "outputId": "93e90021-8340-4f3d-a9f8-ca7fd6fdb56d"
   },
   "outputs": [],
   "source": [
    "# compute model results on test set\n",
    "start = time.time()\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0_djoisO5ru"
   },
   "outputs": [],
   "source": [
    "# generate predictions for model analysis\n",
    "start = time.time()\n",
    "y_pred = model.predict(x_test)\n",
    "y_max = np.argmax(y_pred, axis=1).astype(np.uint8)\n",
    "predictions = [y_max, y_pred]\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to local instance\n",
    "with open(f'{result_path}/{model_id}-{data_id}{note}.pkl', \"wb\") as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "helper.plot_confusion_matrix(y_test, y_max, mode='all', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix counts\n",
    "helper.plot_confusion_matrix(y_test, y_max, mode='all', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colab_lenet_classify_all2.ipynb",
   "provenance": [
    {
     "file_id": "https://gist.github.com/mrgrhn/c6d2a157ebfc883e462f2d6e2ce2e3ce#file-lenet_tensorflow-ipynb",
     "timestamp": 1645028600895
    }
   ]
  },
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
