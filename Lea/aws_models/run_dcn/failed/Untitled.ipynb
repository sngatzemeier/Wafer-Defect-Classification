{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdcf84c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deformable_conv_layer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deformable_conv_layer.py\n",
    "\n",
    "############\n",
    "# AUTHOR: An Jiaoyang\n",
    "# DATE: 2018-10-11\n",
    "############\n",
    "\"\"\"Deformable Convolutional Layer\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "\n",
    "class DeformableConvLayer(Conv2D):\n",
    "    \"\"\"Only support \"channel last\" data format\"\"\"\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 num_deformable_group=None,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"`kernel_size`, `strides` and `dilation_rate` must have the same value in both axis.\n",
    "        :param num_deformable_group: split output channels into groups, offset shared in each group. If\n",
    "        this parameter is None, then set  num_deformable_group=filters.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.kernel = None\n",
    "        self.bias = None\n",
    "        self.offset_layer_kernel = None\n",
    "        self.offset_layer_bias = None\n",
    "        if num_deformable_group is None:\n",
    "            num_deformable_group = filters\n",
    "        if filters % num_deformable_group != 0:\n",
    "            raise ValueError('\"filters\" mod \"num_deformable_group\" must be zero')\n",
    "        self.num_deformable_group = num_deformable_group\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = int(input_shape[-1])\n",
    "        # kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "        # we want to use depth-wise conv\n",
    "        kernel_shape = self.kernel_size + (self.filters * input_dim, 1)\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=kernel_shape,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                name='bias',\n",
    "                shape=(self.filters,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                trainable=True,\n",
    "                dtype=self.dtype)\n",
    "\n",
    "        # create offset conv layer\n",
    "        offset_num = self.kernel_size[0] * self.kernel_size[1] * self.num_deformable_group\n",
    "        self.offset_layer_kernel = self.add_weight(\n",
    "            name='offset_layer_kernel',\n",
    "            shape=self.kernel_size + (input_dim, offset_num * 2),  # 2 means x and y axis\n",
    "            initializer=tf.zeros_initializer(),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        self.offset_layer_bias = self.add_weight(\n",
    "            name='offset_layer_bias',\n",
    "            shape=(offset_num * 2,),\n",
    "            initializer=tf.zeros_initializer(),\n",
    "            # initializer=tf.random_uniform_initializer(-5, 5),\n",
    "            regularizer=self.bias_regularizer,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        # get offset, shape [batch_size, out_h, out_w, filter_h, * filter_w * channel_out * 2]\n",
    "        offset = tf.nn.conv2d(inputs,\n",
    "                              filter=self.offset_layer_kernel,\n",
    "                              strides=[1, *self.strides, 1],\n",
    "                              padding=self.padding.upper(),\n",
    "                              dilations=[1, *self.dilation_rate, 1])\n",
    "        offset += self.offset_layer_bias\n",
    "\n",
    "        # add padding if needed\n",
    "        inputs = self._pad_input(inputs)\n",
    "\n",
    "        # some length\n",
    "        batch_size = int(inputs.get_shape()[0])\n",
    "        channel_in = int(inputs.get_shape()[-1])\n",
    "        in_h, in_w = [int(i) for i in inputs.get_shape()[1: 3]]  # input feature map size\n",
    "        out_h, out_w = [int(i) for i in offset.get_shape()[1: 3]]  # output feature map size\n",
    "        filter_h, filter_w = self.kernel_size\n",
    "\n",
    "        # get x, y axis offset\n",
    "        offset = tf.reshape(offset, [batch_size, out_h, out_w, -1, 2])\n",
    "        y_off, x_off = offset[:, :, :, :, 0], offset[:, :, :, :, 1]\n",
    "\n",
    "        # input feature map gird coordinates\n",
    "        y, x = self._get_conv_indices([in_h, in_w])\n",
    "        y, x = [tf.expand_dims(i, axis=-1) for i in [y, x]]\n",
    "        y, x = [tf.tile(i, [batch_size, 1, 1, 1, self.num_deformable_group]) for i in [y, x]]\n",
    "        y, x = [tf.reshape(i, [*i.shape[0: 3], -1]) for i in [y, x]]\n",
    "        y, x = [tf.to_float(i) for i in [y, x]]\n",
    "\n",
    "        # add offset\n",
    "        y, x = y + y_off, x + x_off\n",
    "        y = tf.clip_by_value(y, 0, in_h - 1)\n",
    "        x = tf.clip_by_value(x, 0, in_w - 1)\n",
    "\n",
    "        # get four coordinates of points around (x, y)\n",
    "        y0, x0 = [tf.to_int32(tf.floor(i)) for i in [y, x]]\n",
    "        y1, x1 = y0 + 1, x0 + 1\n",
    "        # clip\n",
    "        y0, y1 = [tf.clip_by_value(i, 0, in_h - 1) for i in [y0, y1]]\n",
    "        x0, x1 = [tf.clip_by_value(i, 0, in_w - 1) for i in [x0, x1]]\n",
    "\n",
    "        # get pixel values\n",
    "        indices = [[y0, x0], [y0, x1], [y1, x0], [y1, x1]]\n",
    "        p0, p1, p2, p3 = [DeformableConvLayer._get_pixel_values_at_point(inputs, i) for i in indices]\n",
    "\n",
    "        # cast to float\n",
    "        x0, x1, y0, y1 = [tf.to_float(i) for i in [x0, x1, y0, y1]]\n",
    "        # weights\n",
    "        w0 = (y1 - y) * (x1 - x)\n",
    "        w1 = (y1 - y) * (x - x0)\n",
    "        w2 = (y - y0) * (x1 - x)\n",
    "        w3 = (y - y0) * (x - x0)\n",
    "        # expand dim for broadcast\n",
    "        w0, w1, w2, w3 = [tf.expand_dims(i, axis=-1) for i in [w0, w1, w2, w3]]\n",
    "        # bilinear interpolation\n",
    "        pixels = tf.add_n([w0 * p0, w1 * p1, w2 * p2, w3 * p3])\n",
    "\n",
    "        # reshape the \"big\" feature map\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h, out_w, filter_h, filter_w, self.num_deformable_group, channel_in])\n",
    "        pixels = tf.transpose(pixels, [0, 1, 3, 2, 4, 5, 6])\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h * filter_h, out_w * filter_w, self.num_deformable_group, channel_in])\n",
    "\n",
    "        # copy channels to same group\n",
    "        feat_in_group = self.filters // self.num_deformable_group\n",
    "        pixels = tf.tile(pixels, [1, 1, 1, 1, feat_in_group])\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h * filter_h, out_w * filter_w, -1])\n",
    "\n",
    "        # depth-wise conv\n",
    "        out = tf.nn.depthwise_conv2d(pixels, self.kernel, [1, filter_h, filter_w, 1], 'VALID')\n",
    "        # add the output feature maps in the same group\n",
    "        out = tf.reshape(out, [batch_size, out_h, out_w, self.filters, channel_in])\n",
    "        out = tf.reduce_sum(out, axis=-1)\n",
    "        if self.use_bias:\n",
    "            out += self.bias\n",
    "        return self.activation(out)\n",
    "\n",
    "    def _pad_input(self, inputs):\n",
    "        \"\"\"Check if input feature map needs padding, because we don't use the standard Conv() function.\n",
    "        :param inputs:\n",
    "        :return: padded input feature map\n",
    "        \"\"\"\n",
    "        # When padding is 'same', we should pad the feature map.\n",
    "        # if padding == 'same', output size should be `ceil(input / stride)`\n",
    "        if self.padding == 'same':\n",
    "            in_shape = inputs.get_shape().as_list()[1: 3]\n",
    "            padding_list = []\n",
    "            for i in range(2):\n",
    "                filter_size = self.kernel_size[i]\n",
    "                dilation = self.dilation_rate[i]\n",
    "                dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n",
    "                same_output = (in_shape[i] + self.strides[i] - 1) // self.strides[i]\n",
    "                valid_output = (in_shape[i] - dilated_filter_size + self.strides[i]) // self.strides[i]\n",
    "                if same_output == valid_output:\n",
    "                    padding_list += [0, 0]\n",
    "                else:\n",
    "                    p = dilated_filter_size - 1\n",
    "                    p_0 = p // 2\n",
    "                    padding_list += [p_0, p - p_0]\n",
    "            if sum(padding_list) != 0:\n",
    "                padding = [[0, 0],\n",
    "                           [padding_list[0], padding_list[1]],  # top, bottom padding\n",
    "                           [padding_list[2], padding_list[3]],  # left, right padding\n",
    "                           [0, 0]]\n",
    "                inputs = tf.pad(inputs, padding)\n",
    "        return inputs\n",
    "\n",
    "    def _get_conv_indices(self, feature_map_size):\n",
    "        \"\"\"the x, y coordinates in the window when a filter sliding on the feature map\n",
    "        :param feature_map_size:\n",
    "        :return: y, x with shape [1, out_h, out_w, filter_h * filter_w]\n",
    "        \"\"\"\n",
    "        feat_h, feat_w = [int(i) for i in feature_map_size[0: 2]]\n",
    "\n",
    "        x, y = tf.meshgrid(tf.range(feat_w), tf.range(feat_h))\n",
    "        x, y = [tf.reshape(i, [1, *i.get_shape(), 1]) for i in [x, y]]  # shape [1, h, w, 1]\n",
    "        x, y = [tf.image.extract_image_patches(i,\n",
    "                                               [1, *self.kernel_size, 1],\n",
    "                                               [1, *self.strides, 1],\n",
    "                                               [1, *self.dilation_rate, 1],\n",
    "                                               'VALID')\n",
    "                for i in [x, y]]  # shape [1, out_h, out_w, filter_h * filter_w]\n",
    "        return y, x\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_pixel_values_at_point(inputs, indices):\n",
    "        \"\"\"get pixel values\n",
    "        :param inputs:\n",
    "        :param indices: shape [batch_size, H, W, I], I = filter_h * filter_w * channel_out\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        y, x = indices\n",
    "        batch, h, w, n = y.get_shape().as_list()[0: 4]\n",
    "\n",
    "        batch_idx = tf.reshape(tf.range(0, batch), (batch, 1, 1, 1))\n",
    "        b = tf.tile(batch_idx, (1, h, w, n))\n",
    "        pixel_idx = tf.stack([b, y, x], axis=-1)\n",
    "        return tf.gather_nd(inputs, pixel_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b2788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting layers_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile layers_train.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import, division\n",
    "\n",
    "\"\"\"\n",
    "Created on Tue Apr 17 11:43:29 2018\n",
    "@author: xingshuli\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D\n",
    "from keras.initializers import RandomNormal\n",
    "from deform_conv import tf_batch_map_offsets\n",
    "\n",
    "\n",
    "class ConvOffset2D_train(Conv2D):\n",
    "    '''\n",
    "    Convolutional layer responsible for learning the 2D offsets and output the deformed\n",
    "    feature map using bilinear interpolation\n",
    "    Note that this layer does not perform convolution on the deformed feature map\n",
    "    '''\n",
    "\n",
    "    def __init__(self, filters, init_normal_stddev=0.01, **kwargs):\n",
    "        '''\n",
    "        Parameters:\n",
    "        filters: int\n",
    "        Number of channel of the input feature map\n",
    "        init_normal_stddev: float\n",
    "        Normal kernel initialization\n",
    "        **kwargs:\n",
    "        pass to superclass. see the Conv2D layer in keras\n",
    "        '''\n",
    "        self.filters = filters\n",
    "        #super(ConvOffset2D_test, self).__init__(self.filters, **kwargs)\n",
    "        super(ConvOffset2D_train, self).__init__(self.filters * 2, (3, 3), padding = 'same',use_bias = False, kernel_initializer = RandomNormal(0, init_normal_stddev), **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        '''\n",
    "        return the deformed featureed map\n",
    "        '''\n",
    "        x_shape = x.get_shape()\n",
    "        offsets = super(ConvOffset2D_train, self).call(x)\n",
    "\n",
    "        # offsets: (b*c, h, w, 2)\n",
    "        offsets = self._to_bc_h_w_2(offsets, x_shape)\n",
    "        # x: (b*c, h, w)\n",
    "        x = self._to_bc_h_w(x, x_shape)\n",
    "        # X_offset: (b*c, h, w)\n",
    "        x_offset = tf_batch_map_offsets(x, offsets)\n",
    "        # x_offset: (b, h, w, c)\n",
    "        x_offset = self._to_b_h_w_c(x_offset, x_shape)\n",
    "\n",
    "        return x_offset\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        '''\n",
    "        Output shape is the same as input shape\n",
    "        Becauase, this layer only does the deformation part\n",
    "        '''\n",
    "        return input_shape\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_bc_h_w_2(x, x_shape):\n",
    "        '''\n",
    "        (b, h, w, 2c)->(bc, h, w, 2)\n",
    "        '''\n",
    "        x = tf.transpose(x, [0, 3, 1, 2])\n",
    "        x = tf.reshape(x, (-1, int(x_shape[1]), int(x_shape[2]), 2))\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_bc_h_w(x, x_shape):\n",
    "        '''\n",
    "        (b, h, w, c)->(bc, h, w)\n",
    "        '''\n",
    "        x = tf.transpose(x, [0, 3, 1, 2])\n",
    "        x = tf.reshape(x, (-1, int(x_shape[1]), int(x_shape[2])))\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_b_h_w_c(x, x_shape):\n",
    "        '''\n",
    "        (b*c, h, w)->(b, h, w, c)\n",
    "        '''\n",
    "        x = tf.reshape(x, (-1, int(x_shape[3]), int(x_shape[1]), int(x_shape[2])))\n",
    "        x = tf.transpose(x, [0, 2, 3, 1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfe03ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deform_conv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deform_conv.py \n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import, division\n",
    "\"\"\"\n",
    "Created on Wed Mar 28 09:52:58 2018\n",
    "@author: xingshuli\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Map the input array to new coordinates by interpolation\n",
    "from scipy.ndimage.interpolation import map_coordinates as sp_map_coordinates\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#flatten tensor\n",
    "def tf_flatten(a):\n",
    "    return tf.reshape(a, [-1])\n",
    "\n",
    "\n",
    "#Tensorflow version of np.repeat for 1D\n",
    "def tf_repeat(a, repeats, axis = 0):\n",
    "    assert len(a.get_shape()) == 1\n",
    "    a = tf.expand_dims(a, -1)\n",
    "    a = tf.tile(a, [1, repeats])\n",
    "    a = tf_flatten(a)\n",
    "    \n",
    "    return a\n",
    "\n",
    "\n",
    "#Tensorflow version of np.repeat for 2D\n",
    "def tf_repeat_2d(a, repeats):\n",
    "    assert len(a.get_shape()) == 2\n",
    "    a = tf.expand_dims(a, 0)\n",
    "    a = tf.tile(a, [repeats, 1, 1])\n",
    "    return a\n",
    "\n",
    "#Tensorflow version of scipy.ndimage.map_coordinates\n",
    "'''\n",
    "Parameters:\n",
    "input: tf.Tensor. shape = (s, s)\n",
    "coords: tf.Tensor. shape = (n_points, 2)\n",
    "coords_lt -- left-top of coordinates\n",
    "coords_rb -- right-bottom of coordinates\n",
    "coords_lb -- left-bottom of coordinates\n",
    "coords_rt -- right-top of coordinates \n",
    "for mapped_vals is calculated by bilinear interpolation\n",
    "'''\n",
    "def tf_map_coordinates(input, coords, order = 1):\n",
    "    assert order == 1 # '1' means the linear interpolation\n",
    "\n",
    "    coords_lt = tf.cast(tf.floor(coords), 'int32')\n",
    "    coords_rb = tf.cast(tf.ceil(coords), 'int32')\n",
    "    coords_lb = tf.stack([coords_lt[:, 0], coords_rb[:, 1]], axis = 1)\n",
    "    coords_rt = tf.stack([coords_rb[:, 0], coords_lt[:, 1]], axis = 1)\n",
    "    \n",
    "    vals_lt = tf.gather_nd(input, coords_lt)\n",
    "    vals_rb = tf.gather_nd(input, coords_rb)\n",
    "    vals_lb = tf.gather_nd(input, coords_lb)\n",
    "    vals_rt = tf.gather_nd(input, coords_rt)\n",
    "    \n",
    "    coords_offset_lt = coords - tf.cast(coords_lt, 'float32')\n",
    "    vals_t = vals_lt + (vals_rt - vals_lt) * coords_offset_lt[:, 0]\n",
    "    vals_b = vals_lb + (vals_rb - vals_lb) * coords_offset_lt[:, 0]\n",
    "    mapped_vals = vals_t + (vals_b - vals_t) * coords_offset_lt[:, 1]\n",
    "    \n",
    "    return mapped_vals\n",
    "\n",
    "def sp_batch_map_coordinates(inputs, coords):\n",
    "    coords = coords.clip(0, inputs.shape[1] - 1)\n",
    "    mapped_vals = np.array([sp_map_coordinates(input, coord.T, mode = 'nearest', order = 1) \n",
    "                            for input, coord in zip(inputs, coords)])\n",
    "    \n",
    "    return mapped_vals\n",
    "    \n",
    "def tf_batch_map_coordinates(input, coords, order = 1):\n",
    "    #Batch version of tf_map_coordinates\n",
    "    '''\n",
    "    Parameter\n",
    "    input: tf.Tensor. shape = (b, s, s)\n",
    "    coords: tf.Tensor. shape = (b, n_points, 2)\n",
    "    \n",
    "    Return\n",
    "    tf. Tensor. shape = (b, s, s)\n",
    "    '''\n",
    "    input_shape = tf.shape(input)\n",
    "    batch_size = input_shape[0]\n",
    "    input_size = input_shape[1]\n",
    "    n_coords = tf.shape(coords)[1]\n",
    "    \n",
    "    coords = tf.clip_by_value(coords, 0, tf.cast(input_size, 'float32') - 1)\n",
    "    coords_lt = tf.cast(tf.floor(coords), 'int32')\n",
    "    coords_rb = tf.cast(tf.ceil(coords), 'int32')\n",
    "    coords_lb = tf.stack([coords_lt[..., 0], coords_rb[..., 1]], axis=-1)\n",
    "    coords_rt = tf.stack([coords_rb[..., 0], coords_lt[..., 1]], axis=-1)\n",
    "    \n",
    "    idx = tf_repeat(tf.range(batch_size), n_coords)\n",
    "    \n",
    "    def _get_vals_by_coords(input, coords):\n",
    "        indices = tf.stack([idx, tf_flatten(coords[..., 0]), \n",
    "                            tf_flatten(coords[..., 1])], axis=-1)\n",
    "        vals = tf.gather_nd(input, indices)\n",
    "        vals = tf.reshape(vals, (batch_size, n_coords))\n",
    "        return vals\n",
    "\n",
    "    vals_lt = _get_vals_by_coords(input, coords_lt)\n",
    "    vals_rb = _get_vals_by_coords(input, coords_rb)\n",
    "    vals_lb = _get_vals_by_coords(input, coords_lb)\n",
    "    vals_rt = _get_vals_by_coords(input, coords_rt)\n",
    "    \n",
    "    #bilinear interpolation\n",
    "    coords_offset_lt = coords - tf.cast(coords_lt, 'float32')\n",
    "    vals_t = vals_lt + (vals_rt - vals_lt) * coords_offset_lt[..., 0]\n",
    "    vals_b = vals_lb + (vals_rb - vals_lb) * coords_offset_lt[..., 0]\n",
    "    mapped_vals = vals_t + (vals_b - vals_t) * coords_offset_lt[..., 1]\n",
    "    \n",
    "    return mapped_vals\n",
    "    \n",
    "def sp_batch_map_offsets(input, offsets):\n",
    "    '''\n",
    "    Reference implementation for tf_batch_map_offsets\n",
    "    '''\n",
    "    batch_size = input.shape[0]\n",
    "    input_size = input.shape[1]\n",
    "    \n",
    "    offsets = offsets.reshape(batch_size, -1, 2)\n",
    "    grid = np.stack(np.mgrid[:input_size, :input_size], -1).reshape(-1, 2)\n",
    "    grid = np.repeat([grid], batch_size, axis = 0)\n",
    "    coords = offsets + grid\n",
    "    coords = coords.clip(0, input_size - 1)\n",
    "    \n",
    "    mapped_vals = sp_batch_map_coordinates(input, coords)\n",
    "    \n",
    "    return mapped_vals\n",
    "    \n",
    "def tf_batch_map_offsets(input, offsets, order = 1):\n",
    "    '''\n",
    "    Parameters:\n",
    "    \n",
    "    input: tf. Tensor. shape = (b, s, s)\n",
    "    offsets: tf. Tensor. shape = (b, s, s, 2)\n",
    "    \n",
    "    Returns:\n",
    "    tf. Tensor. shape = (b, s, s)\n",
    "    \n",
    "    '''\n",
    "    input_shape = tf.shape(input)\n",
    "    batch_size = input_shape[0]\n",
    "    input_size = input_shape[1]\n",
    "    \n",
    "    offsets = tf.reshape(offsets, (batch_size, -1, 2))\n",
    "    grid = tf.meshgrid(tf.range(input_size), tf.range(input_size), indexing = 'ij')\n",
    "    grid = tf.stack(grid, axis = -1)\n",
    "    grid = tf.cast(grid, 'float32')\n",
    "    grid = tf.reshape(grid, (-1, 2))\n",
    "    grid = tf_repeat_2d(grid, batch_size)\n",
    "    coords = grid + offsets\n",
    "    \n",
    "    mapped_vals = tf_batch_map_coordinates(input, coords)\n",
    "    \n",
    "    return mapped_vals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
