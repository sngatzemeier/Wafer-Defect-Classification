{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GoogLeNet as Classify Model\n",
    "Following GoogLeNet implementation from this [blog](https://ai.plainenglish.io/googlenet-inceptionv1-with-tensorflow-9e7f3a161e87)\n",
    "\n",
    "Use GoogLeNet to classify defect patterns only (i.e., as an alternative to Yu classify model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17709,
     "status": "ok",
     "timestamp": 1645132611467,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "CXt05UtlLUcz",
    "outputId": "b11f0ff9-5b3e-4c8e-96f5-d1554a2330c0"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, losses, optimizers, callbacks\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import helpers as helper\n",
    "from keras_model_s3_wrapper import *\n",
    "\n",
    "import boto3\n",
    "import pickle5 as pickle\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'wafer-capstone'\n",
    "my_bucket = s3.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5182,
     "status": "ok",
     "timestamp": 1645132634411,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "ihcdTQ1BL37k",
    "outputId": "3552479a-c162-49dd-d2aa-43e97da39ea3"
   },
   "outputs": [],
   "source": [
    "# specify variables for model\n",
    "path = 'data'\n",
    "result_path = 'results'\n",
    "model_path = '../saved_models'\n",
    "\n",
    "filename = 'WM-clean-paper'\n",
    "option = '-classify' # -classify, -knn\n",
    "map_column = 'waferMap224'\n",
    "\n",
    "model_id = 'yudetect'\n",
    "data_id = 'paper'\n",
    "note = '' # -optional\n",
    "\n",
    "x = 60\n",
    "y = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train, dev, and test sets\n",
    "# directly from S3 (using boto3 resource)\n",
    "start = time.time()\n",
    "\n",
    "train_key = f'{path}/{filename}-train{option}.pkl'\n",
    "dev_key = f'{path}/{filename}-dev.pkl'\n",
    "test_key = f'{path}/{filename}-test.pkl'\n",
    "\n",
    "train = pickle.loads(my_bucket.Object(train_key).get()['Body'].read())\n",
    "dev = pickle.loads(my_bucket.Object(dev_key).get()['Body'].read())\n",
    "test = pickle.loads(my_bucket.Object(test_key).get()['Body'].read())\n",
    "\n",
    "# remove nones from dev and test\n",
    "\n",
    "dev = dev[dev.classifyLabels != 8].reset_index(drop=True)\n",
    "test = test[test.classifyLabels != 8].reset_index(drop=True)\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "print(f\"Train: {len(train)}\")\n",
    "print(f\"Dev: {len(dev)}\")\n",
    "print(f\"Test: {len(test)}\")\n",
    "\n",
    "print(f\"Sanity check: {np.unique(train[map_column][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load train, dev, and test sets\n",
    "# # directly from S3 (using boto3 client)\n",
    "# start = time.time()\n",
    "\n",
    "# s3 = boto3.client('s3')\n",
    "# bucket_name = 'wafer-capstone'\n",
    "\n",
    "# obj = s3.get_object(Bucket = bucket_name, Key = f'{path}/{filename}-train{option}.pkl')\n",
    "# body = obj['Body'].read()\n",
    "# train = pickle.loads(body)\n",
    "\n",
    "# obj = s3.get_object(Bucket = bucket_name, Key = f'{path}/{filename}-dev.pkl')\n",
    "# body = obj['Body'].read()\n",
    "# dev = pickle.loads(body)\n",
    "\n",
    "# obj = s3.get_object(Bucket = bucket_name, Key = f'{path}/{filename}-test.pkl')\n",
    "# body = obj['Body'].read()\n",
    "# test = pickle.loads(body)\n",
    "\n",
    "# print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# print(f\"Train: {len(train)}\")\n",
    "# print(f\"Dev: {len(dev)}\")\n",
    "# print(f\"Test: {len(test)}\")\n",
    "\n",
    "# print(f\"Sanity check: {np.unique(train[map_column][0]),}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load train, dev, and test sets\n",
    "# # from local instance\n",
    "# start = time.time()\n",
    "\n",
    "# with open(f'{path}/{filename}-train{option}.pkl', \"rb\") as fh:\n",
    "#     train = pickle.load(fh)\n",
    "# with open(f'{path}/{filename}-dev.pkl', \"rb\") as fh:\n",
    "#     dev = pickle.load(fh)\n",
    "# with open(f'{path}/{filename}-test.pkl', \"rb\") as fh:\n",
    "#     test = pickle.load(fh)\n",
    "\n",
    "# print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# print(f\"Train: {len(train)}\")\n",
    "# print(f\"Dev: {len(dev)}\")\n",
    "# print(f\"Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train failure type distribution\n",
    "helper.defect_distribution(train, note='Train Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev failure type distribution\n",
    "helper.defect_distribution(dev, note='Dev Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test failure type distribution\n",
    "helper.defect_distribution(test, note='Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1645132865773,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "RI680iu4MC89",
    "outputId": "525e0142-8e7c-4039-8556-506728753008"
   },
   "outputs": [],
   "source": [
    "# prepare inputs\n",
    "start = time.time()\n",
    "\n",
    "x_train = np.stack(train[map_column])\n",
    "x_val = np.stack(dev[map_column])\n",
    "x_test = np.stack(test[map_column])\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# sanity check\n",
    "# expected: (#rows, xdim, ydim)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3527,
     "status": "ok",
     "timestamp": 1645132869397,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "vnSKfJpVMGka",
    "outputId": "b606f84b-deb5-4618-b5cd-70b19ab4db1d"
   },
   "outputs": [],
   "source": [
    "# expand tensor and repeat 3 times\n",
    "# images in greyscale, so no channel dimension\n",
    "start = time.time()\n",
    "\n",
    "x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
    "x_val = tf.expand_dims(x_val, axis=3, name=None)\n",
    "x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
    "\n",
    "x_train = tf.repeat(x_train, 3, axis=3)\n",
    "x_val = tf.repeat(x_val, 3, axis=3)\n",
    "x_test = tf.repeat(x_test, 3, axis=3)\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# sanity check\n",
    "# expected: TensorShape([#rows, xdim, ydim, 3])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645132869398,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "BWtyDAx8MTXN"
   },
   "outputs": [],
   "source": [
    "# prepare labels for supervised learning\n",
    "# note: make sure labels are integers if using sparse categorical cross entropy\n",
    "start = time.time()\n",
    "\n",
    "y_train = np.asarray(train['detectLabels']).astype(np.uint8)\n",
    "y_val = np.asarray(dev['detectLabels']).astype(np.uint8)\n",
    "y_test = np.asarray(test['detectLabels']).astype(np.uint8)\n",
    "\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "# sanity check\n",
    "# expected: type = int, min = 0, max = 7\n",
    "print(type(y_train[0]))\n",
    "print(min(y_train), min(y_val), min(y_test))\n",
    "print(max(y_train), max(y_val), max(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1645132869398,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "6wKcYCdaLcFU"
   },
   "outputs": [],
   "source": [
    "def inception(x,\n",
    "              filters_1x1,\n",
    "              filters_3x3_reduce,\n",
    "              filters_3x3,\n",
    "              filters_5x5_reduce,\n",
    "              filters_5x5,\n",
    "              filters_pool):\n",
    "  path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "  path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "  path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n",
    "\n",
    "  path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "  path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n",
    "\n",
    "  path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "  path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n",
    "\n",
    "  return tf.concat([path1, path2, path3, path4], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1164,
     "status": "ok",
     "timestamp": 1645132870558,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "nDEI1TMtLcHq"
   },
   "outputs": [],
   "source": [
    "# REMOVE RESIZING IF USING 224x224\n",
    "\n",
    "inp = layers.Input(shape=(x, y, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"neighbor\", input_shape=x_train.shape[1:])(inp)\n",
    "\n",
    "x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_tensor)\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n",
    "\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=64,\n",
    "              filters_3x3_reduce=96,\n",
    "              filters_3x3=128,\n",
    "              filters_5x5_reduce=16,\n",
    "              filters_5x5=32,\n",
    "              filters_pool=32)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=128,\n",
    "              filters_3x3_reduce=128,\n",
    "              filters_3x3=192,\n",
    "              filters_5x5_reduce=32,\n",
    "              filters_5x5=96,\n",
    "              filters_pool=64)\n",
    "\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=192,\n",
    "              filters_3x3_reduce=96,\n",
    "              filters_3x3=208,\n",
    "              filters_5x5_reduce=16,\n",
    "              filters_5x5=48,\n",
    "              filters_pool=64)\n",
    "\n",
    "aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
    "aux1 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n",
    "aux1 = layers.Flatten()(aux1)\n",
    "aux1 = layers.Dense(1024, activation='relu')(aux1)\n",
    "aux1 = layers.Dropout(0.7)(aux1)\n",
    "aux1 = layers.Dense(10, activation='softmax')(aux1)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=160,\n",
    "              filters_3x3_reduce=112,\n",
    "              filters_3x3=224,\n",
    "              filters_5x5_reduce=24,\n",
    "              filters_5x5=64,\n",
    "              filters_pool=64)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=128,\n",
    "              filters_3x3_reduce=128,\n",
    "              filters_3x3=256,\n",
    "              filters_5x5_reduce=24,\n",
    "              filters_5x5=64,\n",
    "              filters_pool=64)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=112,\n",
    "              filters_3x3_reduce=144,\n",
    "              filters_3x3=288,\n",
    "              filters_5x5_reduce=32,\n",
    "              filters_5x5=64,\n",
    "              filters_pool=64)\n",
    "\n",
    "aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
    "aux2 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n",
    "aux2 = layers.Flatten()(aux2)\n",
    "aux2 = layers.Dense(1024, activation='relu')(aux2)\n",
    "aux2 = layers.Dropout(0.7)(aux2)\n",
    "aux2 = layers.Dense(10, activation='softmax')(aux2)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=256,\n",
    "              filters_3x3_reduce=160,\n",
    "              filters_3x3=320,\n",
    "              filters_5x5_reduce=32,\n",
    "              filters_5x5=128,\n",
    "              filters_pool=128)\n",
    "\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=256,\n",
    "              filters_3x3_reduce=160,\n",
    "              filters_3x3=320,\n",
    "              filters_5x5_reduce=32,\n",
    "              filters_5x5=128,\n",
    "              filters_pool=128)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=384,\n",
    "              filters_3x3_reduce=192,\n",
    "              filters_3x3=384,\n",
    "              filters_5x5_reduce=48,\n",
    "              filters_5x5=128,\n",
    "              filters_pool=128)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "out = layers.Dense(9, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1645132870559,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "WzIFlLP9LcLQ"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs = inp, outputs = [out, aux1, aux2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1645132870559,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "wJjdIxC1aWwO"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=[losses.sparse_categorical_crossentropy, losses.sparse_categorical_crossentropy, losses.sparse_categorical_crossentropy], loss_weights=[1, 0.3, 0.3], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7528885,
     "status": "ok",
     "timestamp": 1645140399441,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "VofnKKKoauYX",
    "outputId": "d026fd8d-1dfe-4c3d-8140-55ca20315a1b"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, [y_train, y_train, y_train], validation_data=(x_val, [y_val, y_val, y_val]), batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1645140400109,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "53UluuOE5TX_",
    "outputId": "ce8952a6-0b5c-4d20-f5a1-e77d8565eeab"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].plot(history.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend(['Train','Val'])\n",
    "\n",
    "axs[1].plot(history.history['dense_4_accuracy'])\n",
    "axs[1].plot(history.history['val_dense_4_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to local instance\n",
    "model.save(f'{model_path}/{model_id}-{data_id}{note}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to S3\n",
    "s3_save_keras_model(model, f'{model_id}-{data_id}{note}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83193,
     "status": "ok",
     "timestamp": 1645140483298,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "iNbFiTZW5dQ7",
    "outputId": "ed7deb4d-e490-4fad-df54-c790df902473"
   },
   "outputs": [],
   "source": [
    "# compute model results on test set\n",
    "start = time.time()\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"Wall time: {:.2f} seconds\".format(time.time() - start))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for model analysis\n",
    "start = time.time()\n",
    "pred = model.predict(x_test)\n",
    "y_pred = np.argmax(pred[0], axis=1)\n",
    "predictions = [y_pred, pred]\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "# save to local instance\n",
    "with open(f'{result_path}/{model_id}-{data_id}{note}.pkl', \"wb\") as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "helper.plot_confusion_matrix(y_test, y_pred, mode='classify', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix counts\n",
    "helper.plot_confusion_matrix(y_test, y_pred, mode='classify', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colab_googlenet_classify_all.ipynb",
   "provenance": [
    {
     "file_id": "https://gist.github.com/mrgrhn/a6ad98dbc81f3ec8f73d39415452de9a#file-googlenet_tensorflow-ipynb",
     "timestamp": 1645042556321
    }
   ]
  },
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
