{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GoogLeNet as Classify Model\n",
    "Following GoogLeNet implementation from this [blog](https://ai.plainenglish.io/googlenet-inceptionv1-with-tensorflow-9e7f3a161e87)\n",
    "\n",
    "Use GoogLeNet to classify defect patterns only. Data was resized to 224x224 and median filtered 7x7. Classes were augmented to max class count using random flips and rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17709,
     "status": "ok",
     "timestamp": 1645132611467,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "CXt05UtlLUcz",
    "outputId": "b11f0ff9-5b3e-4c8e-96f5-d1554a2330c0"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses, optimizers\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "\n",
    "import helpers as helper\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.transform import resize as sk_resize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5182,
     "status": "ok",
     "timestamp": 1645132634411,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "ihcdTQ1BL37k",
    "outputId": "3552479a-c162-49dd-d2aa-43e97da39ea3"
   },
   "outputs": [],
   "source": [
    "# specify variables for model\n",
    "path = '../../data'\n",
    "filename = 'WM-clean-id224filter7'\n",
    "option = '-clsaug' # -clsaug, -detund\n",
    "map_column = 'filterMap7'\n",
    "label_column = 'classifyLabels'\n",
    "filetype = 'zip' # zip, pkl\n",
    "\n",
    "model_id = 'googlenet'\n",
    "result_path = '../../results'\n",
    "note = 'filtered' # -optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train, dev, and test sets\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "if filetype == 'pkl':\n",
    "    # open pkl files\n",
    "    with open(f'{path}/{filename}-train{option}.pkl', \"rb\") as fh:\n",
    "        train = pickle.load(fh)\n",
    "    with open(f'{path}/{filename}-dev.pkl', \"rb\") as fh:\n",
    "        dev = pickle.load(fh)\n",
    "    with open(f'{path}/{filename}-test.pkl', \"rb\") as fh:\n",
    "        test = pickle.load(fh)\n",
    "\n",
    "elif filetype == 'zip':\n",
    "    train = helper.load(f'{path}/{filename}-train{option}.zip')\n",
    "    dev = helper.load(f'{path}/{filename}-dev.zip')\n",
    "    test = helper.load(f'{path}/{filename}-test.zip')\n",
    "\n",
    "# remove none type from dev and test sets\n",
    "dev = dev[dev.failureType != 'none']\n",
    "test = test[test.failureType != 'none']\n",
    "\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "print()\n",
    "print(f\"Train: {len(train)}\")\n",
    "print(f\"Dev: {len(dev)}\")\n",
    "print(f\"Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # resize images to 60x60 in preparation for model\n",
    "# start = time.time()\n",
    "\n",
    "# train['resized_map'] = train.waferMap.apply(lambda x: sk_resize(x, [60, 60], anti_aliasing=True))\n",
    "# dev['resized_map'] = dev.waferMap.apply(lambda x: sk_resize(x, [60, 60], anti_aliasing=True))\n",
    "# test['resized_map'] = test.waferMap.apply(lambda x: sk_resize(x, [60, 60], anti_aliasing=True))\n",
    "\n",
    "# print(\"Wall time: {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1645132865773,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "RI680iu4MC89",
    "outputId": "525e0142-8e7c-4039-8556-506728753008"
   },
   "outputs": [],
   "source": [
    "# prepare inputs\n",
    "start = time.time()\n",
    "\n",
    "x_train = np.stack(train['resized_map'])\n",
    "x_val = np.stack(dev['resized_map'])\n",
    "x_test = np.stack(test['resized_map'])\n",
    "\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "\n",
    "# sanity check\n",
    "# expected: (#rows, xdim, ydim)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3527,
     "status": "ok",
     "timestamp": 1645132869397,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "vnSKfJpVMGka",
    "outputId": "b606f84b-deb5-4618-b5cd-70b19ab4db1d"
   },
   "outputs": [],
   "source": [
    "# expand tensor and repeat 3 times\n",
    "# images in greyscale, so no channel dimension\n",
    "start = time.time()\n",
    "x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
    "x_val = tf.expand_dims(x_val, axis=3, name=None)\n",
    "x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
    "\n",
    "x_train = tf.repeat(x_train, 3, axis=3)\n",
    "x_val = tf.repeat(x_val, 3, axis=3)\n",
    "x_test = tf.repeat(x_test, 3, axis=3)\n",
    "\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "\n",
    "# sanity check\n",
    "# expected: TensorShape([#rows, xdim, ydim, 3])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645132869398,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "BWtyDAx8MTXN"
   },
   "outputs": [],
   "source": [
    "# prepare labels for supervised learning\n",
    "# note: make sure labels are integers if using sparse categorical cross entropy\n",
    "y_train = np.asarray(train[label_column]).astype('int64')\n",
    "y_val = np.asarray(dev[label_column]).astype('int64')\n",
    "y_test = np.asarray(test[label_column]).astype('int64')\n",
    "\n",
    "# sanity check\n",
    "# expected: type = int, min = 0, max = 7\n",
    "print(type(y_train[0]))\n",
    "print(min(y_train), min(y_val), min(y_test))\n",
    "print(max(y_train), max(y_val), max(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1645132869398,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "6wKcYCdaLcFU"
   },
   "outputs": [],
   "source": [
    "def inception(x,\n",
    "              filters_1x1,\n",
    "              filters_3x3_reduce,\n",
    "              filters_3x3,\n",
    "              filters_5x5_reduce,\n",
    "              filters_5x5,\n",
    "              filters_pool):\n",
    "  path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "  path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "  path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n",
    "\n",
    "  path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "  path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n",
    "\n",
    "  path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "  path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n",
    "\n",
    "  return tf.concat([path1, path2, path3, path4], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1164,
     "status": "ok",
     "timestamp": 1645132870558,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "nDEI1TMtLcHq"
   },
   "outputs": [],
   "source": [
    "inp = layers.Input(shape=(32, 32, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(inp)\n",
    "\n",
    "x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_tensor)\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n",
    "\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=64,\n",
    "              filters_3x3_reduce=96,\n",
    "              filters_3x3=128,\n",
    "              filters_5x5_reduce=16,\n",
    "              filters_5x5=32,\n",
    "              filters_pool=32)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=128,\n",
    "              filters_3x3_reduce=128,\n",
    "              filters_3x3=192,\n",
    "              filters_5x5_reduce=32,\n",
    "              filters_5x5=96,\n",
    "              filters_pool=64)\n",
    "\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=192,\n",
    "              filters_3x3_reduce=96,\n",
    "              filters_3x3=208,\n",
    "              filters_5x5_reduce=16,\n",
    "              filters_5x5=48,\n",
    "              filters_pool=64)\n",
    "\n",
    "aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
    "aux1 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n",
    "aux1 = layers.Flatten()(aux1)\n",
    "aux1 = layers.Dense(1024, activation='relu')(aux1)\n",
    "aux1 = layers.Dropout(0.7)(aux1)\n",
    "aux1 = layers.Dense(10, activation='softmax')(aux1)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=160,\n",
    "              filters_3x3_reduce=112,\n",
    "              filters_3x3=224,\n",
    "              filters_5x5_reduce=24,\n",
    "              filters_5x5=64,\n",
    "              filters_pool=64)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=128,\n",
    "              filters_3x3_reduce=128,\n",
    "              filters_3x3=256,\n",
    "              filters_5x5_reduce=24,\n",
    "              filters_5x5=64,\n",
    "              filters_pool=64)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=112,\n",
    "              filters_3x3_reduce=144,\n",
    "              filters_3x3=288,\n",
    "              filters_5x5_reduce=32,\n",
    "              filters_5x5=64,\n",
    "              filters_pool=64)\n",
    "\n",
    "aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
    "aux2 = layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n",
    "aux2 = layers.Flatten()(aux2)\n",
    "aux2 = layers.Dense(1024, activation='relu')(aux2)\n",
    "aux2 = layers.Dropout(0.7)(aux2)\n",
    "aux2 = layers.Dense(10, activation='softmax')(aux2)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=256,\n",
    "              filters_3x3_reduce=160,\n",
    "              filters_3x3=320,\n",
    "              filters_5x5_reduce=32,\n",
    "              filters_5x5=128,\n",
    "              filters_pool=128)\n",
    "\n",
    "x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=256,\n",
    "              filters_3x3_reduce=160,\n",
    "              filters_3x3=320,\n",
    "              filters_5x5_reduce=32,\n",
    "              filters_5x5=128,\n",
    "              filters_pool=128)\n",
    "\n",
    "x = inception(x,\n",
    "              filters_1x1=384,\n",
    "              filters_3x3_reduce=192,\n",
    "              filters_3x3=384,\n",
    "              filters_5x5_reduce=48,\n",
    "              filters_5x5=128,\n",
    "              filters_pool=128)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "out = layers.Dense(9, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1645132870559,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "WzIFlLP9LcLQ"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs = inp, outputs = [out, aux1, aux2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1645132870559,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "wJjdIxC1aWwO"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=[losses.sparse_categorical_crossentropy, losses.sparse_categorical_crossentropy, losses.sparse_categorical_crossentropy], loss_weights=[1, 0.3, 0.3], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7528885,
     "status": "ok",
     "timestamp": 1645140399441,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "VofnKKKoauYX",
    "outputId": "d026fd8d-1dfe-4c3d-8140-55ca20315a1b"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, [y_train, y_train, y_train], validation_data=(x_val, [y_val, y_val, y_val]), batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1645140400109,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "53UluuOE5TX_",
    "outputId": "ce8952a6-0b5c-4d20-f5a1-e77d8565eeab"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].plot(history.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend(['Train','Val'])\n",
    "\n",
    "axs[1].plot(history.history['dense_4_accuracy'])\n",
    "axs[1].plot(history.history['val_dense_4_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83193,
     "status": "ok",
     "timestamp": 1645140483298,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64",
      "userId": "08012892845319420981"
     },
     "user_tz": 300
    },
    "id": "iNbFiTZW5dQ7",
    "outputId": "ed7deb4d-e490-4fad-df54-c790df902473"
   },
   "outputs": [],
   "source": [
    "# compute model results on test set\n",
    "start = time.time()\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "print()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for model analysis\n",
    "start = time.time()\n",
    "pred = model.predict(x_test)\n",
    "y_pred = np.argmax(pred[0], axis=1)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results, history, and predictions\n",
    "with open(f'{result_path}/{model_id}-{filename}{option}{note}.pkl', \"wb\") as f:\n",
    "    pickle.dump(pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(f'{result_path}/{model_id}-{filename}{option}{note}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "helper.plot_confusion_matrix(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix counts\n",
    "helper.plot_confusion_matrix(y_test, y_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colab_googlenet_classify_all.ipynb",
   "provenance": [
    {
     "file_id": "https://gist.github.com/mrgrhn/a6ad98dbc81f3ec8f73d39415452de9a#file-googlenet_tensorflow-ipynb",
     "timestamp": 1645042556321
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
