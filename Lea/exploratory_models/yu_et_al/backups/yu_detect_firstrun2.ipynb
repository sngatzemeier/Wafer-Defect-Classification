{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSGNJKWAVg6Q"
   },
   "source": [
    "#### Detect model from Yu, et al\n",
    "Implementation of the detection model from the Yu, et al [paper](https://drive.google.com/file/d/1nYl4w41CAcj8XwTEdVwcD5lVheUFIHVy/view?usp=sharing)\n",
    "\n",
    "Data was resized to 224x224 and median filtered 7x7. None type was subsampled to keep only 30,000 random samples.\n",
    "\n",
    "Refinement on first run. Still tries to follow the paper as closely as possible, but some changes from the first run:\n",
    "- Added last fully connected layer (FC3) that was accidentally omitted in the first run.\n",
    "- Saved both model and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMcWUHT5-eVD"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses, optimizers\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "\n",
    "import helpers as helper\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAINOC_mVg6V"
   },
   "outputs": [],
   "source": [
    "# specify variables for model\n",
    "path = '../../../data/resized224'\n",
    "filename = 'WM-clean-id224filter7'\n",
    "option = '-detund' # -clsaug, -detund\n",
    "map_column = 'filterMap7'\n",
    "label_column = 'detectLabels'\n",
    "filetype = 'zip' # zip, pkl\n",
    "\n",
    "model_id = 'yudetect'\n",
    "result_path = '../results'\n",
    "note = '-firstrun2' # -optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qC9z2Ht7k0RL"
   },
   "outputs": [],
   "source": [
    "# load train, dev, and test sets\n",
    "if filetype == 'pkl':\n",
    "    # open pkl files\n",
    "    with open(f'{path}/{filename}-train{option}.pkl', \"rb\") as fh:\n",
    "        train = pickle.load(fh)\n",
    "    with open(f'{path}/{filename}-dev.pkl', \"rb\") as fh:\n",
    "        dev = pickle.load(fh)\n",
    "    with open(f'{path}/{filename}-test.pkl', \"rb\") as fh:\n",
    "        test = pickle.load(fh)\n",
    "\n",
    "elif filetype == 'zip':\n",
    "    train = helper.load(f'{path}/{filename}-train{option}.zip')\n",
    "    dev = helper.load(f'{path}/{filename}-dev.zip')\n",
    "    test = helper.load(f'{path}/{filename}-test.zip')\n",
    "\n",
    "print(f\"Train: {len(train)}\")\n",
    "print(f\"Dev: {len(dev)}\")\n",
    "print(f\"Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15kW5d5-Vg6W"
   },
   "source": [
    "#### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDQak4kDQzAW"
   },
   "outputs": [],
   "source": [
    "# baseline accuracy of test set\n",
    "nones = len(test[test.failureType == 'none'])\n",
    "total = len(test)\n",
    "print(f\"Baseline accuracy: {nones/total*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y393njcaVg6X"
   },
   "outputs": [],
   "source": [
    "# train failure type distribution\n",
    "helper.defect_distribution(train, note='Train Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LXbUFl1Vg6Y"
   },
   "outputs": [],
   "source": [
    "# dev failure type distribution\n",
    "helper.defect_distribution(dev, note='Dev Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWkI2NBCVg6Y"
   },
   "outputs": [],
   "source": [
    "# test failure type distribution\n",
    "helper.defect_distribution(test, note='Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hk0oXgoRVg6Z"
   },
   "source": [
    "#### Data set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poThmiyAoHSi"
   },
   "outputs": [],
   "source": [
    "# prepare inputs\n",
    "start = time.time()\n",
    "\n",
    "x_train = np.stack(train[map_column])\n",
    "x_val = np.stack(dev[map_column])\n",
    "x_test = np.stack(test[map_column])\n",
    "\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "\n",
    "# sanity check\n",
    "# expected: (#rows, xdim, ydim)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy_dVa44ZOLk"
   },
   "outputs": [],
   "source": [
    "# expand tensor and create dummy dimension at axis 3\n",
    "# images in greyscale, so no channel dimension\n",
    "start = time.time()\n",
    "\n",
    "x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
    "x_val = tf.expand_dims(x_val, axis=3, name=None)\n",
    "x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
    "\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "\n",
    "# sanity check\n",
    "# expected: TensorShape([#rows, xdim, ydim, 1])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIS8zJfn_aDO"
   },
   "outputs": [],
   "source": [
    "# prepare labels for supervised learning\n",
    "# note: make sure labels are integers if using sparse categorical cross entropy\n",
    "y_train = np.asarray(train[label_column]).astype('int64')\n",
    "y_val = np.asarray(dev[label_column]).astype('int64')\n",
    "y_test = np.asarray(test[label_column]).astype('int64')\n",
    "\n",
    "# sanity check\n",
    "# expected: type = int\n",
    "type(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI90-ZiOVg6a"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeaLkOM-XRZA"
   },
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='sigmoid'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOAJW5ByhYCl"
   },
   "outputs": [],
   "source": [
    "# set model optimizer and metrics\n",
    "opt = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xv-ml2R6hw_V"
   },
   "outputs": [],
   "source": [
    "# run model\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfX0d7zyocFw"
   },
   "outputs": [],
   "source": [
    "# visualize accuracy and loss history\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].plot(history.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].legend(['Train', 'Val'])\n",
    "\n",
    "axs[1].plot(history.history['accuracy'])\n",
    "axs[1].plot(history.history['val_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxMhUP1KVg6c"
   },
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLQqDljamZTV"
   },
   "outputs": [],
   "source": [
    "# compute model results on test set\n",
    "start = time.time()\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "print()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0_djoisO5ru"
   },
   "outputs": [],
   "source": [
    "# generate predictions for model analysis\n",
    "start = time.time()\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjvZ9iKpVg6c"
   },
   "outputs": [],
   "source": [
    "# save results, history, and predictions\n",
    "with open(f'{result_path}/{model_id}-{filename}{option}{note}.pkl', \"wb\") as f:\n",
    "    pickle.dump(y_pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_EldUXTVg6c"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(f'{result_path}/{model_id}-{filename}{option}{note}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W66QX4L3Vg6d"
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "helper.plot_confusion_matrix(y_test, y_pred, mode='detect', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLjZdZBNVg6d"
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix counts\n",
    "helper.plot_confusion_matrix(y_test, y_pred, mode='detect', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PmliDThVg6d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "yu_detect_firstrun2.ipynb",
   "provenance": [
    {
     "file_id": "https://gist.github.com/mrgrhn/c6d2a157ebfc883e462f2d6e2ce2e3ce#file-lenet_tensorflow-ipynb",
     "timestamp": 1645028600895
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
